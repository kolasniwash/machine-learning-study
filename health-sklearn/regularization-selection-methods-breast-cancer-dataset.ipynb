{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Methods Investigation Using Breast Cancert Dataset\n",
    "\n",
    "\n",
    "Objectives for this notebook:\n",
    "- Implement sklearn pipelines applied to various models\n",
    "- Use gridsearch with different regularization techniques\n",
    "- Implement a step forward variable selection algorithm\n",
    "\n",
    "Types of regularization:\n",
    "1. Lasso & Ridge\n",
    "2. ElastoNet\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import librarys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('dark')\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate the data and understand the features. Load in DataFrame format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>mean_compactness</th>\n",
       "      <th>mean_concavity</th>\n",
       "      <th>mean_concave_points</th>\n",
       "      <th>mean_symmetry</th>\n",
       "      <th>mean_fractal_dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst_texture</th>\n",
       "      <th>worst_perimeter</th>\n",
       "      <th>worst_area</th>\n",
       "      <th>worst_smoothness</th>\n",
       "      <th>worst_compactness</th>\n",
       "      <th>worst_concavity</th>\n",
       "      <th>worst_concave_points</th>\n",
       "      <th>worst_symmetry</th>\n",
       "      <th>worst_fractal_dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness  mean_compactness  mean_concavity  mean_concave_points  mean_symmetry  mean_fractal_dimension  ...  worst_texture  worst_perimeter  worst_area  worst_smoothness  worst_compactness  worst_concavity  worst_concave_points  worst_symmetry  worst_fractal_dimension  target\n",
       "0        17.99         10.38          122.80     1001.0          0.11840           0.27760          0.3001              0.14710         0.2419                 0.07871  ...          17.33           184.60      2019.0            0.1622             0.6656           0.7119                0.2654          0.4601                  0.11890       0\n",
       "1        20.57         17.77          132.90     1326.0          0.08474           0.07864          0.0869              0.07017         0.1812                 0.05667  ...          23.41           158.80      1956.0            0.1238             0.1866           0.2416                0.1860          0.2750                  0.08902       0\n",
       "2        19.69         21.25          130.00     1203.0          0.10960           0.15990          0.1974              0.12790         0.2069                 0.05999  ...          25.53           152.50      1709.0            0.1444             0.4245           0.4504                0.2430          0.3613                  0.08758       0\n",
       "3        11.42         20.38           77.58      386.1          0.14250           0.28390          0.2414              0.10520         0.2597                 0.09744  ...          26.50            98.87       567.7            0.2098             0.8663           0.6869                0.2575          0.6638                  0.17300       0\n",
       "4        20.29         14.34          135.10     1297.0          0.10030           0.13280          0.1980              0.10430         0.1809                 0.05883  ...          16.67           152.20      1575.0            0.1374             0.2050           0.4000                0.1625          0.2364                  0.07678       0\n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "#extract data\n",
    "features, target = data.data, data.target\n",
    "\n",
    "#create dataframe\n",
    "data = pd.DataFrame(features, columns=data.feature_names)\n",
    "\n",
    "#join the target column\n",
    "data = pd.concat([data, pd.DataFrame(target)], axis=1)\n",
    "\n",
    "#rename the target column\n",
    "data.rename(columns={0: 'target'}, inplace=True)\n",
    "\n",
    "#remove the spaced in the columns headers\n",
    "data.columns = data.columns.str.replace(\" \", \"_\")\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "1. Data should be normalized before classifiying\n",
    "2. Relatively small data set. Use kfold validation on all model types.\n",
    "2. There are 30 features that likely have colinearity. Consider PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: nan, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:,-1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5938375350140056"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "212/357"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper functions\n",
    "\n",
    "- **load_data** - Retrieves the data from sklearn\n",
    "- **get_train_test** - Splits the data in train and test\n",
    "- **classify_model** - Takes in a model, and applied gridsearch. Returns the best model paramers, roc auc score, classification report, and model results report\n",
    "- **pipeline_pca** - A pipeline that takes a model and applies standard scaler and pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funciton to load the data\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Function to load the data in numpy array format.\n",
    "    \n",
    "    Use for input to the Classifier pipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = load_breast_cancer()\n",
    "    X, Y = data.data, data.target\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(train_size=0.7, random_state=99):\n",
    "    \"\"\"\n",
    "    \n",
    "    Loads the data.\n",
    "    Returns X and Y test and train sets.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    X, Y = load_data()\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y)#, train_size=train_size, random_state=random_state)\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_model(model, parameters, score='roc_auc'):\n",
    "    \n",
    "    \"\"\"\n",
    "    General function for implementing grid search with validation to any model.\n",
    "    \n",
    "    Returns \n",
    "    \n",
    "    \"\"\"\n",
    "    #load the train and test sets\n",
    "    X_train, X_test, Y_train, Y_test = get_train_test(X, Y)\n",
    "    \n",
    "    #initalize kfolds\n",
    "    kf = KFold(10, random_state=99)\n",
    "    \n",
    "    #initalize the grid search of the selected model\n",
    "    #call return_train_score true to include training scores in the results output\n",
    "    model_gs = GridSearchCV(model, parameters, cv=kf, scoring=score, return_train_score=True)\n",
    "    \n",
    "    #fit the model\n",
    "    model_gs.fit(X_train.astype(float), Y_train)\n",
    "    \n",
    "    #get model predictions\n",
    "    Y_predictions = model_gs.predict(X_test.astype(float))\n",
    "    \n",
    "    #return various scoring metrics for model\n",
    "    cr = classification_report(Y_test, Y_predictions)\n",
    "    \n",
    "    #calcualte the ROC AUC value and print with the best parameters\n",
    "    roc_score = roc_auc_score(Y_test, Y_predictions)\n",
    "    print('ROC AUC Score for Hold-Out set: {}'.format(roc_score), end='\\n')\n",
    "    \n",
    "    #print the best parameters from model\n",
    "    print('Best model parameters {}'.format(model_gs.best_params_), end=\"\\n\")\n",
    "    \n",
    "    \n",
    "    return roc_score, pd.DataFrame(model_gs.cv_results_), cr\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_pca(model):\n",
    "    \"\"\"\n",
    "    Creates a pipeline using scaler, pca, and the input model\n",
    "    \n",
    "    Returns the pipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    pca = PCA()\n",
    "    \n",
    "    pipe = make_pipeline(scaler, pca, model)\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Classifier\n",
    "\n",
    "Default settings for logistic regression classifier are to use l1 regularization with liblinear. In this case want to see the performance of the classifier without it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score for Hold-Out set: 0.9895833333333333\n",
      "Best model parameters {'logisticregression__C': 0.01, 'logisticregression__class_weight': 'balanced', 'logisticregression__penalty': 'none', 'pca__n_components': 0.9}\n",
      "CPU times: user 31 s, sys: 7.22 s, total: 38.2 s\n",
      "Wall time: 9.75 s\n"
     ]
    }
   ],
   "source": [
    "#use the lbfgs solver on the classifier so we can infvestiagte performnce of no regularization\n",
    "logistic = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "#c is the weight of the regularization in the model\n",
    "c_space = [0.01, 0.1, 1, 10, 50, 100, 300]\n",
    "\n",
    "#class weight is the representaiton of the class imblance. In this dataset class 1 accounts for 60% of the classes.\n",
    "#try a range of balancing weights. balanced balance data. \n",
    "class_weights = ['balanced', {0:6, 1:4}, {0:1, 1:1}]\n",
    "\n",
    "penalty = ['none']\n",
    "\n",
    "parameter_logistic = {'pca__n_components' : [0.80, 0.90, 0.95],\n",
    "                      'logisticregression__C' : c_space,\n",
    "                      'logisticregression__class_weight': class_weights,\n",
    "                     'logisticregression__penalty': penalty}\n",
    "\n",
    "pipe = pipeline_pca(logistic)\n",
    "\n",
    "#run grid seearch on the classifier\n",
    "%time _, results_lr, report_lr = classify_model(pipe, parameter_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95        54\n",
      "           1       0.98      0.97      0.97        89\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.96      0.96      0.96       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to see the combinations of the training paramerters we can call results_lr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregression__class_weight': {0: 1, 1: 1}, 'logisticregression__penalty': 'none', 'pca__n_components': 0.8}</td>\n",
       "      <td>0.995468</td>\n",
       "      <td>0.99402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregression__class_weight': {0: 1, 1: 1}, 'logisticregression__penalty': 'none', 'pca__n_components': 0.8}</td>\n",
       "      <td>0.995468</td>\n",
       "      <td>0.99402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 50, 'logisticregression__class_weight': {0: 1, 1: 1}, 'logisticregression__penalty': 'none', 'pca__n_components': 0.8}</td>\n",
       "      <td>0.995468</td>\n",
       "      <td>0.99402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 300, 'logisticregression__class_weight': {0: 1, 1: 1}, 'logisticregression__penalty': 'none', 'pca__n_components': 0.8}</td>\n",
       "      <td>0.995468</td>\n",
       "      <td>0.99402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregression__class_weight': {0: 1, 1: 1}, 'logisticregression__penalty': 'none', 'pca__n_components': 0.8}</td>\n",
       "      <td>0.995468</td>\n",
       "      <td>0.99402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score                                                                                                                                              params  mean_train_score  mean_test_score\n",
       "15                1   {'logisticregression__C': 0.1, 'logisticregression__class_weight': {0: 1, 1: 1}, 'logisticregression__penalty': 'none', 'pca__n_components': 0.8}          0.995468          0.99402\n",
       "33                1    {'logisticregression__C': 10, 'logisticregression__class_weight': {0: 1, 1: 1}, 'logisticregression__penalty': 'none', 'pca__n_components': 0.8}          0.995468          0.99402\n",
       "42                1    {'logisticregression__C': 50, 'logisticregression__class_weight': {0: 1, 1: 1}, 'logisticregression__penalty': 'none', 'pca__n_components': 0.8}          0.995468          0.99402\n",
       "60                1   {'logisticregression__C': 300, 'logisticregression__class_weight': {0: 1, 1: 1}, 'logisticregression__penalty': 'none', 'pca__n_components': 0.8}          0.995468          0.99402\n",
       "6                 1  {'logisticregression__C': 0.01, 'logisticregression__class_weight': {0: 1, 1: 1}, 'logisticregression__penalty': 'none', 'pca__n_components': 0.8}          0.995468          0.99402"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_cols = ['rank_test_score', 'params', 'mean_train_score', 'mean_test_score']\n",
    "results_lr[result_cols].sort_values('mean_test_score', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the top 5 scores used a pca of 0.8. It is likely we should try tuning for lower pca values.\n",
    "\n",
    "Also note that the imblance in the classes did not have strong change in the train/test scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso & Ridge Classifierer\n",
    "\n",
    "A lasso classifier is essentially logistic regression with L1 regularization. Similarly, Ridge regression uses 'l2' regularization. So we can add this as a parameter in our grid search call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score for Hold-Out set: 0.9742726877985237\n",
      "Best model parameters {'logisticregression__C': 0.1, 'logisticregression__class_weight': {0: 6, 1: 4}, 'logisticregression__penalty': 'l1', 'pca__n_components': 0.9}\n",
      "CPU times: user 38.8 s, sys: 9.35 s, total: 48.1 s\n",
      "Wall time: 12.3 s\n"
     ]
    }
   ],
   "source": [
    "lsso_ridge = LogisticRegression(solver='liblinear')\n",
    "\n",
    "#c is the weight of the regularization in the model\n",
    "c_space = [0.01, 0.1, 1, 10, 50, 100, 300]\n",
    "\n",
    "#class weight is the representaiton of the class imblance. In this dataset class 1 accounts for 60% of the classes.\n",
    "#try a range of balancing weights. balanced balance data. \n",
    "class_weights = ['balanced', {0:6, 1:4}, {0:1, 1:1}]\n",
    "\n",
    "#penalties indicate the kind of regression we are performing. l1 is lasso, and l2 is ridge\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "parameter_lsso_ridge = {'pca__n_components' : [0.80, 0.90, 0.95],\n",
    "                      'logisticregression__C' : c_space,\n",
    "                      'logisticregression__class_weight': class_weights,\n",
    "                     'logisticregression__penalty' : penalty}\n",
    "\n",
    "pipe_lso_rdg = pipeline_pca(lsso_ridge)\n",
    "\n",
    "%time _, results_lso, report_lso = classify_model(pipe_lso_rdg, parameter_lsso_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93        53\n",
      "           1       0.95      0.98      0.96        90\n",
      "\n",
      "    accuracy                           0.95       143\n",
      "   macro avg       0.95      0.94      0.95       143\n",
      "weighted avg       0.95      0.95      0.95       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report_lso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregression__class_weight': {0: 1, 1: 1}, 'logisticregression__penalty': 'l1', 'pca__n_components': 0.9}</td>\n",
       "      <td>0.996840</td>\n",
       "      <td>0.995899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregression__class_weight': {0: 1, 1: 1}, 'logisticregression__penalty': 'l1', 'pca__n_components': 0.95}</td>\n",
       "      <td>0.997128</td>\n",
       "      <td>0.995899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "      <td>{'logisticregression__C': 50, 'logisticregression__class_weight': {0: 1, 1: 1}, 'logisticregression__penalty': 'l1', 'pca__n_components': 0.9}</td>\n",
       "      <td>0.997020</td>\n",
       "      <td>0.995671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "      <td>{'logisticregression__C': 50, 'logisticregression__class_weight': {0: 1, 1: 1}, 'logisticregression__penalty': 'l2', 'pca__n_components': 0.9}</td>\n",
       "      <td>0.997020</td>\n",
       "      <td>0.995671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregression__class_weight': {0: 1, 1: 1}, 'logisticregression__penalty': 'l1', 'pca__n_components': 0.9}</td>\n",
       "      <td>0.997023</td>\n",
       "      <td>0.995671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rank_test_score                                                                                                                                           params  mean_train_score  mean_test_score\n",
       "49                 1    {'logisticregression__C': 1, 'logisticregression__class_weight': {0: 1, 1: 1}, 'logisticregression__penalty': 'l1', 'pca__n_components': 0.9}          0.996840         0.995899\n",
       "50                 1   {'logisticregression__C': 1, 'logisticregression__class_weight': {0: 1, 1: 1}, 'logisticregression__penalty': 'l1', 'pca__n_components': 0.95}          0.997128         0.995899\n",
       "85                 3   {'logisticregression__C': 50, 'logisticregression__class_weight': {0: 1, 1: 1}, 'logisticregression__penalty': 'l1', 'pca__n_components': 0.9}          0.997020         0.995671\n",
       "88                 3   {'logisticregression__C': 50, 'logisticregression__class_weight': {0: 1, 1: 1}, 'logisticregression__penalty': 'l2', 'pca__n_components': 0.9}          0.997020         0.995671\n",
       "103                3  {'logisticregression__C': 100, 'logisticregression__class_weight': {0: 1, 1: 1}, 'logisticregression__penalty': 'l1', 'pca__n_components': 0.9}          0.997023         0.995671"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_lso[result_cols].sort_values('mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElastoNet Classifier\n",
    "\n",
    "Similar to Lasso and Ridge, the parmeters in logistic regression offer an option to apply both L1 and L2 regularization at the same time. This is known as ElastoNet regularization.\n",
    "\n",
    "The elastonet regularization can only be used with the 'saga' solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score for Hold-Out set: 0.9470443349753696\n",
      "Best model parameters {'logisticregression__C': 0.1, 'logisticregression__class_weight': 'balanced', 'logisticregression__l1_ratio': 0.1, 'logisticregression__penalty': 'elasticnet', 'pca__n_components': 0.95}\n",
      "CPU times: user 2min 44s, sys: 38.4 s, total: 3min 22s\n",
      "Wall time: 51.9 s\n"
     ]
    }
   ],
   "source": [
    "elasto = LogisticRegression(solver='saga')\n",
    "\n",
    "#c is the weight of the regularization in the model\n",
    "c_space = [0.01, 0.1, 1, 10, 50, 100, 300]\n",
    "\n",
    "#class weight is the representaiton of the class imblance. In this dataset class 1 accounts for 60% of the classes.\n",
    "#try a range of balancing weights. balanced balance data. \n",
    "class_weights = ['balanced', {0:6, 1:4}, {0:1, 1:1}]\n",
    "\n",
    "#penalties indicate the kind of regression we are performing. l1 is lasso, and l2 is ridge\n",
    "penalty = ['elasticnet']\n",
    "\n",
    "#defines the mixing of the l1 and l2 regularization. l1=0 means use l2 regularization.\n",
    "l1_ratio = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "parameter_elasto = {'pca__n_components' : [0.80, 0.90, 0.95],\n",
    "                      'logisticregression__C' : c_space,\n",
    "                      'logisticregression__class_weight': class_weights,\n",
    "                     'logisticregression__penalty' : penalty,\n",
    "                   'logisticregression__l1_ratio' : l1_ratio}\n",
    "\n",
    "pipe_elasso = pipeline_pca(elasto)\n",
    "\n",
    "%time _, results_elaso, report_elaso = classify_model(pipe_elasso, parameter_elasto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        56\n",
      "           1       0.95      0.97      0.96        87\n",
      "\n",
      "    accuracy                           0.95       143\n",
      "   macro avg       0.95      0.95      0.95       143\n",
      "weighted avg       0.95      0.95      0.95       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report_elaso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregression__class_weight': 'balanced', 'logisticregression__l1_ratio': 0.1, 'logisticregression__penalty': 'elasticnet', 'pca__n_components': 0.95}</td>\n",
       "      <td>0.997989</td>\n",
       "      <td>0.997372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregression__class_weight': 'balanced', 'logisticregression__l1_ratio': 0.9, 'logisticregression__penalty': 'elasticnet', 'pca__n_components': 0.95}</td>\n",
       "      <td>0.998587</td>\n",
       "      <td>0.997372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregression__class_weight': {0: 6, 1: 4}, 'logisticregression__l1_ratio': 0.5, 'logisticregression__penalty': 'elasticnet', 'pca__n_components': 0.95}</td>\n",
       "      <td>0.998467</td>\n",
       "      <td>0.997372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 1, 'logisticregression__class_weight': {0: 1, 1: 1}, 'logisticregression__l1_ratio': 0.9, 'logisticregression__penalty': 'elasticnet', 'pca__n_components': 0.95}</td>\n",
       "      <td>0.998537</td>\n",
       "      <td>0.997372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregression__class_weight': {0: 1, 1: 1}, 'logisticregression__l1_ratio': 0.1, 'logisticregression__penalty': 'elasticnet', 'pca__n_components': 0.95}</td>\n",
       "      <td>0.997931</td>\n",
       "      <td>0.997372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rank_test_score                                                                                                                                                                                         params  mean_train_score  mean_test_score\n",
       "47                 1    {'logisticregression__C': 0.1, 'logisticregression__class_weight': 'balanced', 'logisticregression__l1_ratio': 0.1, 'logisticregression__penalty': 'elasticnet', 'pca__n_components': 0.95}          0.997989         0.997372\n",
       "104                1      {'logisticregression__C': 1, 'logisticregression__class_weight': 'balanced', 'logisticregression__l1_ratio': 0.9, 'logisticregression__penalty': 'elasticnet', 'pca__n_components': 0.95}          0.998587         0.997372\n",
       "68                 1  {'logisticregression__C': 0.1, 'logisticregression__class_weight': {0: 6, 1: 4}, 'logisticregression__l1_ratio': 0.5, 'logisticregression__penalty': 'elasticnet', 'pca__n_components': 0.95}          0.998467         0.997372\n",
       "134                1    {'logisticregression__C': 1, 'logisticregression__class_weight': {0: 1, 1: 1}, 'logisticregression__l1_ratio': 0.9, 'logisticregression__penalty': 'elasticnet', 'pca__n_components': 0.95}          0.998537         0.997372\n",
       "77                 1  {'logisticregression__C': 0.1, 'logisticregression__class_weight': {0: 1, 1: 1}, 'logisticregression__l1_ratio': 0.1, 'logisticregression__penalty': 'elasticnet', 'pca__n_components': 0.95}          0.997931         0.997372"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_elaso[result_cols].sort_values('mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation of results\n",
    "\n",
    "Classifier performance appears independent of the C space and the balancing used. We will interpret the results from setting C to 0.1 and class weight to balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score for Hold-Out set: 0.9567191283292978\n",
      "Best model parameters {'logisticregression__C': 0.1, 'logisticregression__class_weight': 'balanced', 'logisticregression__l1_ratio': 0.9, 'logisticregression__penalty': 'elasticnet', 'pca__n_components': 0.9}\n",
      "CPU times: user 6.39 s, sys: 1.47 s, total: 7.85 s\n",
      "Wall time: 2.01 s\n"
     ]
    }
   ],
   "source": [
    "parameter_elasto = {'pca__n_components' : [0.80, 0.90, 0.95],\n",
    "                      'logisticregression__C' : [0.1],\n",
    "                      'logisticregression__class_weight': ['balanced'],\n",
    "                     'logisticregression__penalty' : penalty,\n",
    "                   'logisticregression__l1_ratio' : l1_ratio}\n",
    "\n",
    "%time _, results_elaso, report_elaso = classify_model(pipe_elasso, parameter_elasto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        59\n",
      "           1       0.96      0.96      0.96        84\n",
      "\n",
      "    accuracy                           0.96       143\n",
      "   macro avg       0.96      0.96      0.96       143\n",
      "weighted avg       0.96      0.96      0.96       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report_elaso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregression__class_weight': 'balanced', 'logisticregression__l1_ratio': 0.9, 'logisticregression__penalty': 'elasticnet', 'pca__n_components': 0.9}</td>\n",
       "      <td>0.993930</td>\n",
       "      <td>0.993606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregression__class_weight': 'balanced', 'logisticregression__l1_ratio': 0.9, 'logisticregression__penalty': 'elasticnet', 'pca__n_components': 0.95}</td>\n",
       "      <td>0.993924</td>\n",
       "      <td>0.993606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregression__class_weight': 'balanced', 'logisticregression__l1_ratio': 0.7, 'logisticregression__penalty': 'elasticnet', 'pca__n_components': 0.9}</td>\n",
       "      <td>0.994149</td>\n",
       "      <td>0.993557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregression__class_weight': 'balanced', 'logisticregression__l1_ratio': 0.7, 'logisticregression__penalty': 'elasticnet', 'pca__n_components': 0.95}</td>\n",
       "      <td>0.994149</td>\n",
       "      <td>0.993557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregression__class_weight': 'balanced', 'logisticregression__l1_ratio': 0.3, 'logisticregression__penalty': 'elasticnet', 'pca__n_components': 0.9}</td>\n",
       "      <td>0.994598</td>\n",
       "      <td>0.993247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score                                                                                                                                                                                       params  mean_train_score  mean_test_score\n",
       "13                1   {'logisticregression__C': 0.1, 'logisticregression__class_weight': 'balanced', 'logisticregression__l1_ratio': 0.9, 'logisticregression__penalty': 'elasticnet', 'pca__n_components': 0.9}          0.993930         0.993606\n",
       "14                1  {'logisticregression__C': 0.1, 'logisticregression__class_weight': 'balanced', 'logisticregression__l1_ratio': 0.9, 'logisticregression__penalty': 'elasticnet', 'pca__n_components': 0.95}          0.993924         0.993606\n",
       "10                3   {'logisticregression__C': 0.1, 'logisticregression__class_weight': 'balanced', 'logisticregression__l1_ratio': 0.7, 'logisticregression__penalty': 'elasticnet', 'pca__n_components': 0.9}          0.994149         0.993557\n",
       "11                3  {'logisticregression__C': 0.1, 'logisticregression__class_weight': 'balanced', 'logisticregression__l1_ratio': 0.7, 'logisticregression__penalty': 'elasticnet', 'pca__n_components': 0.95}          0.994149         0.993557\n",
       "4                 5   {'logisticregression__C': 0.1, 'logisticregression__class_weight': 'balanced', 'logisticregression__l1_ratio': 0.3, 'logisticregression__penalty': 'elasticnet', 'pca__n_components': 0.9}          0.994598         0.993247"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_elaso[result_cols].sort_values('mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing C to 0.1 and class weight to balance showed a reduction in the performance (unlikely this reduction of 0.4% is significant). It did allow us to see greater sensitivity of the l1_ratio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step forward selection\n",
    "\n",
    "This is a brute force method to find the features that result in the best model fit. To implement this we will define a new pipeline with just MinMaxScaler and the selected model. The model will be Linear Regression with l2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_min_max(model):\n",
    "    \"\"\"\n",
    "    Creates a pipeline using scaler, pca, and the input model\n",
    "    \n",
    "    Returns the pipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    min_max = MinMaxScaler()\n",
    "    \n",
    "    pipe = make_pipeline(min_max, model)\n",
    "    \n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following function tests the performance of a logistic regression classifier on indivdual columns. If a column performs better than a previous benchmark it will filter the other columns and use the last column. Best performaning columns will be selected as the final feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_forward_selection(dataframe, target, model, parameters):\n",
    "    \n",
    "    #create a set from the columns in the input dataframe\n",
    "    remaining = set(dataframe.columns)\n",
    "    \n",
    "    #remove the target variable from the set\n",
    "    remaining.remove(target)\n",
    "    \n",
    "    #initalize an array to hold the best features, and set two scores for comparison.\n",
    "    selected = []\n",
    "    current_score, best_new_score = 0.0, 0.0\n",
    "    \n",
    "    #loop while remaining has features in the list and that the current score = best score\n",
    "    while remaining and current_score == best_new_score:\n",
    "        #store the scores from the current set of columns\n",
    "        scores_with_candidates = []\n",
    "        \n",
    "        #loop through the features in remaining\n",
    "        for candidate in remaining:\n",
    "            \n",
    "            X = dataframe[candidate]\n",
    "            Y = dataframe[target]\n",
    "            \n",
    "            #setup the model in a pipeline\n",
    "            pipe = pipeline_min_max(model)\n",
    "            \n",
    "            #run the modified classifer model\n",
    "            score, _, _ = classify_model_sf(X, Y, pipe, parameters)\n",
    "            \n",
    "            #append the score and canditate label\n",
    "            scores_with_candidates.append((score, candidate))\n",
    "            \n",
    "        #sort the set. last element is highest value     \n",
    "        scores_with_candidates.sort()\n",
    "        \n",
    "        #assign the highest score and best candidate\n",
    "        best_new_score, best_candidate = scores_with_candidates.pop()\n",
    "        \n",
    "        #compare accuracy. if better, assign the new score and feature to the selected candidates\n",
    "        if current_score > best_new_score:\n",
    "            remaining.remove(best_candidate)\n",
    "            selected.append(best_candidate)\n",
    "            current_score = best_new_score\n",
    "    \n",
    "    print('Selected features: \\n {}'.format(selected))\n",
    "    \n",
    "    \n",
    "    X = dataframe[candidate]\n",
    "    Y = dataframe[target]\n",
    "            \n",
    "    #setup the model in a pipeline\n",
    "    pipe = pipeline_min_max(model)\n",
    "            \n",
    "    #run the modified classifer model\n",
    "    score, results_sf, report_sf = classify_model_sf(X, Y, pipe, parameters)\n",
    "    \n",
    "    return results_sf, report_sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_model_sf(X, Y, model, parameters, score='roc_auc'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Modified classify function for use in the step forward selection function.\n",
    "    \n",
    "    General function for implementing grid search with validation to any model.\n",
    "    \n",
    "    Returns \n",
    "    \n",
    "    \"\"\"\n",
    "    #load the train and test sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=99)\n",
    "    \n",
    "    #initalize kfolds\n",
    "    kf = KFold(10, random_state=99)\n",
    "    \n",
    "    #initalize the grid search of the selected model\n",
    "    #call return_train_score true to include training scores in the results output\n",
    "    model_gs = GridSearchCV(model, parameters, cv=kf, scoring=score, return_train_score=True)\n",
    "    \n",
    "    #fit the model\n",
    "    model_gs.fit(X_train.astype(float), Y_train)\n",
    "    \n",
    "    #get model predictions\n",
    "    Y_predictions = model_gs.predict(X_test.astype(float))\n",
    "    \n",
    "    #return various scoring metrics for model\n",
    "    cr = classification_report(Y_test, Y_predictions)\n",
    "    \n",
    "    #calcualte the ROC AUC value and print with the best parameters\n",
    "    roc_score = roc_auc_score(Y_test, Y_predictions)\n",
    "    print('ROC AUC Score for Hold-Out set: {}'.format(roc_score), end='\\n')\n",
    "    \n",
    "    #print the best parameters from model\n",
    "    print('Best model parameters {}'.format(model_gs.best_params_), end=\"\\n\")\n",
    "    \n",
    "    \n",
    "    return roc_score, pd.DataFrame(model_gs.cv_results_), cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 493.8  579.1  401.5  392.   471.3  928.8  477.3  819.8  260.9  264.\n  221.8  566.2  599.4  453.1  826.8  693.7  520.  1041.   519.8  462.\n  918.6  568.9  244.5  493.1  451.1 1075.   432.2  963.7 1092.   668.6\n 1077.   610.7 1320.   428.   523.8 1297.   455.3 1686.   514.   399.8\n  337.7  644.8  371.5  320.8  508.8  719.5  857.6  933.1  502.5  658.8\n  994.   365.6  546.3  492.1  633.   457.9  170.4  310.8  527.2  980.5\n  466.7  307.3  701.9  673.7  758.6  788.5  553.5  551.7 1138.  1068.\n  461.4  689.5  407.4 2499.   800.  1419.  1123.   644.2  433.8 1288.\n  449.9  712.8  465.4  519.4  420.3 2501.   246.3  412.5  395.7 1306.\n  402.7  904.6  504.8 1264.   744.7 1878.   507.9  990.   143.5  559.2\n 1145.   340.9  370.   629.9 1482.   606.5  541.6 1191.   290.9  431.9\n 1110.   290.2  584.8  662.7  716.6  464.1  366.5  594.2 1152.   476.5\n 1076.   294.5  245.2  951.6  558.1  992.1  948.   618.4  445.3 1214.\n  509.2 1407.  1261.   363.7  641.2  651.9  378.2  609.1  285.7 1052.\n  566.3  578.3 1206.   412.7  813.7  403.3  387.3  489.   390.  1104.\n  588.9 1162.  1364.   684.5  373.9  991.7 1546.   492.9  651.   418.7\n  684.5  448.6  590.   269.4  432.  1299.   982.   288.5  668.3  623.9\n  475.9  520.2 1260.   381.9  552.4  514.5 1207.   408.8  386.3  403.1\n 1491.   656.1  761.7  680.9  928.2  632.6 1157.  1747.   441.   599.5\n  373.2  495.   280.5  514.3  203.9 1326.   546.4  904.3  682.5  257.8\n 1250.   585.9  928.3  998.9 1130.   674.5  629.8  412.6  600.4  273.9\n  477.4  477.1  248.7  409.1  361.6  506.3  384.6  321.6  575.5  469.1\n  646.1  446.  1148.   731.3  597.8  394.1  761.3 1138.   512.2  616.5\n  477.3  384.8  689.4 1230.   537.3  793.2  880.2  705.6  602.4  506.3\n  748.9  329.6  559.2  455.8  716.9  463.7 1223.   573.2  525.2  347.\n  698.8  389.4 1386.   716.6  476.3  678.1  704.4  399.8  366.8  446.2\n  840.4  912.7  402.   575.3  782.7  432.8  595.9  286.3  271.2  221.2\n  546.1 1245.   324.2  426.   386.8  666.   437.6  485.8  807.2  464.4\n  403.5  338.3  710.6  664.9  575.3  358.9  489.9  420.3  501.3  516.6\n  234.3  596.6  538.4  690.2  747.2  633.1 1404.   503.2  668.7  391.2\n  404.9  766.6 1194.   371.1  512.  1670.   561.   421.   817.7  440.6\n  981.6  674.8  426.7 1076.   803.1  496.4 1509.   530.2  585.   955.1\n 1311.   396.5  380.3 1761.   805.1  336.1  311.9 1132.   466.5  481.6\n  432.   372.7  408.2  485.6 1308.   441.3 1001.   360.5  537.9  420.5\n  466.1  571.1  930.9 1006.   512.2  640.7  431.1 1264.   781.   230.9\n  381.1  713.3 2010.   416.2  685.9  920.6 1102.   419.8  584.1  445.2\n  645.7 1007.   534.6  271.3  272.5  520.   289.7  288.1  578.9 1155.\n  838.1  224.5  561.3  302.4 1384.   409.  1169.   664.7 1024.   250.5\n  984.6  317.5  869.5].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-204-05f85313262e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m          'logisticregression__class_weight': ['balanced']}\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mresults_sf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_sf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_forward_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogistic_sf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-197-7e9fc3f71ba1>\u001b[0m in \u001b[0;36mstep_forward_selection\u001b[0;34m(dataframe, target, model, parameters)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m#run the modified classifer model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_model_sf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m#append the score and canditate label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-198-61a3e7309db9>\u001b[0m in \u001b[0;36mclassify_model_sf\u001b[0;34m(X, Y, model, parameters, score)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mmodel_gs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m#get model predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bk_py3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bk_py3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bk_py3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bk_py3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bk_py3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bk_py3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bk_py3/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bk_py3/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bk_py3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bk_py3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bk_py3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bk_py3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    354\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m~/anaconda3/envs/bk_py3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    318\u001b[0m             \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bk_py3/lib/python3.6/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bk_py3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bk_py3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bk_py3/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bk_py3/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    351\u001b[0m         X = check_array(X, copy=self.copy,\n\u001b[1;32m    352\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                         force_all_finite=\"allow-nan\")\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mdata_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bk_py3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 493.8  579.1  401.5  392.   471.3  928.8  477.3  819.8  260.9  264.\n  221.8  566.2  599.4  453.1  826.8  693.7  520.  1041.   519.8  462.\n  918.6  568.9  244.5  493.1  451.1 1075.   432.2  963.7 1092.   668.6\n 1077.   610.7 1320.   428.   523.8 1297.   455.3 1686.   514.   399.8\n  337.7  644.8  371.5  320.8  508.8  719.5  857.6  933.1  502.5  658.8\n  994.   365.6  546.3  492.1  633.   457.9  170.4  310.8  527.2  980.5\n  466.7  307.3  701.9  673.7  758.6  788.5  553.5  551.7 1138.  1068.\n  461.4  689.5  407.4 2499.   800.  1419.  1123.   644.2  433.8 1288.\n  449.9  712.8  465.4  519.4  420.3 2501.   246.3  412.5  395.7 1306.\n  402.7  904.6  504.8 1264.   744.7 1878.   507.9  990.   143.5  559.2\n 1145.   340.9  370.   629.9 1482.   606.5  541.6 1191.   290.9  431.9\n 1110.   290.2  584.8  662.7  716.6  464.1  366.5  594.2 1152.   476.5\n 1076.   294.5  245.2  951.6  558.1  992.1  948.   618.4  445.3 1214.\n  509.2 1407.  1261.   363.7  641.2  651.9  378.2  609.1  285.7 1052.\n  566.3  578.3 1206.   412.7  813.7  403.3  387.3  489.   390.  1104.\n  588.9 1162.  1364.   684.5  373.9  991.7 1546.   492.9  651.   418.7\n  684.5  448.6  590.   269.4  432.  1299.   982.   288.5  668.3  623.9\n  475.9  520.2 1260.   381.9  552.4  514.5 1207.   408.8  386.3  403.1\n 1491.   656.1  761.7  680.9  928.2  632.6 1157.  1747.   441.   599.5\n  373.2  495.   280.5  514.3  203.9 1326.   546.4  904.3  682.5  257.8\n 1250.   585.9  928.3  998.9 1130.   674.5  629.8  412.6  600.4  273.9\n  477.4  477.1  248.7  409.1  361.6  506.3  384.6  321.6  575.5  469.1\n  646.1  446.  1148.   731.3  597.8  394.1  761.3 1138.   512.2  616.5\n  477.3  384.8  689.4 1230.   537.3  793.2  880.2  705.6  602.4  506.3\n  748.9  329.6  559.2  455.8  716.9  463.7 1223.   573.2  525.2  347.\n  698.8  389.4 1386.   716.6  476.3  678.1  704.4  399.8  366.8  446.2\n  840.4  912.7  402.   575.3  782.7  432.8  595.9  286.3  271.2  221.2\n  546.1 1245.   324.2  426.   386.8  666.   437.6  485.8  807.2  464.4\n  403.5  338.3  710.6  664.9  575.3  358.9  489.9  420.3  501.3  516.6\n  234.3  596.6  538.4  690.2  747.2  633.1 1404.   503.2  668.7  391.2\n  404.9  766.6 1194.   371.1  512.  1670.   561.   421.   817.7  440.6\n  981.6  674.8  426.7 1076.   803.1  496.4 1509.   530.2  585.   955.1\n 1311.   396.5  380.3 1761.   805.1  336.1  311.9 1132.   466.5  481.6\n  432.   372.7  408.2  485.6 1308.   441.3 1001.   360.5  537.9  420.5\n  466.1  571.1  930.9 1006.   512.2  640.7  431.1 1264.   781.   230.9\n  381.1  713.3 2010.   416.2  685.9  920.6 1102.   419.8  584.1  445.2\n  645.7 1007.   534.6  271.3  272.5  520.   289.7  288.1  578.9 1155.\n  838.1  224.5  561.3  302.4 1384.   409.  1169.   664.7 1024.   250.5\n  984.6  317.5  869.5].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "#initate a default logistic regression model to run the step forward selection on\n",
    "\n",
    "logistic_sf = LogisticRegression(solver='liblinear')\n",
    "\n",
    "params = {'logisticregression__C': [0.1],\n",
    "         'logisticregression__class_weight': ['balanced']}\n",
    "\n",
    "results_sf, report_sf = step_forward_selection(data, 'target', logistic_sf, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
